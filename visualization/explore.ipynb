{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/anaconda3/envs/ndg2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/disk1/anaconda3/envs/ndg2/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /mnt/disk1/anaconda3/envs/ndg2/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEENS6_INS2_12MemoryFormatEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset, DataLoader, ConcatDataset\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE \n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "transf = transforms.Compose([\n",
    "                              transforms.CenterCrop(224),  # Crops a central square patch of the image 224 because torchvision's AlexNet needs a 224x224 input!\n",
    "                              transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
    "                              transforms.Normalize(means,stds) # Normalizes tensor with mean and standard deviation\n",
    "])\n",
    "\n",
    "def photo_transform(data):\n",
    "    transf_data = transf(data)\n",
    "    transf_data.domain_id = 1\n",
    "    return transf_data\n",
    "\n",
    "def art_transform(data):\n",
    "    transf_data = transf(data)\n",
    "    transf_data.domain_id = 2\n",
    "    return transf_data\n",
    "\n",
    "def cartoon_transform(data):\n",
    "    transf_data = transf(data)\n",
    "    transf_data.domain_id = 3\n",
    "    return transf_data\n",
    "\n",
    "def sketch_transform(data):\n",
    "    transf_data = transf(data)\n",
    "    transf_data.domain_id = 4\n",
    "    return transf_data\n",
    "\n",
    "device = 'cuda:1'\n",
    "num_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def draw_ellipse(position, covariance, ax=None, **kwargs):\n",
    "    \"\"\"Draw an ellipse with a given position and covariance\"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Convert covariance to principal axes\n",
    "    if covariance.shape == (2, 2):\n",
    "        U, s, Vt = np.linalg.svd(covariance)\n",
    "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "        width, height = 2 * np.sqrt(s)\n",
    "    else:\n",
    "        angle = 0\n",
    "        width, height = 2 * np.sqrt(covariance)\n",
    "    \n",
    "    # Draw the ellipse\n",
    "    for nsig in range(1, 4):\n",
    "        ax.add_patch(Ellipse(position, nsig * width, nsig * height,\n",
    "                             angle, **kwargs))\n",
    "\n",
    "def plot_gmm(gmm, X, label=True, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    labels = gmm.fit(X).predict(X)\n",
    "    if label:\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
    "    else:\n",
    "        ax.scatter(X[:, 0], X[:, 1], s=40, zorder=2)\n",
    "    ax.axis('equal')\n",
    "    \n",
    "    w_factor = 0.2 / gmm.weights_.max()\n",
    "    for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n",
    "        draw_ellipse(pos, covar, alpha=w * w_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_photo = '../data/pacs_v1.0/photo/'\n",
    "dir_art = '../data/pacs_v1.0/art_painting/'\n",
    "dir_cartoon = '../data/pacs_v1.0/cartoon/'\n",
    "dir_sketch = '../data/pacs_v1.0/sketch/'\n",
    "\n",
    "photo_dataset = ImageFolder(dir_photo, transform=photo_transform)\n",
    "art_dataset = ImageFolder(dir_art, transform=art_transform)\n",
    "cartoon_dataset = ImageFolder(dir_cartoon, transform=cartoon_transform)\n",
    "sketch_dataset = ImageFolder(dir_sketch, transform=sketch_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photo Dataset: 1670\n",
      "Art Dataset: 2048\n",
      "Cartoon Dataset: 2344\n",
      "Sketch Dataset: 3929\n"
     ]
    }
   ],
   "source": [
    "print(f\"Photo Dataset: {len(photo_dataset)}\")\n",
    "print(f\"Art Dataset: {len(art_dataset)}\")\n",
    "print(f\"Cartoon Dataset: {len(cartoon_dataset)}\")\n",
    "print(f\"Sketch Dataset: {len(sketch_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_train_dataset, photo_test_dataset = torch.utils.data.random_split(photo_dataset, [1336, 334])\n",
    "art_train_dataset, art_test_dataset = torch.utils.data.random_split(art_dataset, [1638, 410])\n",
    "cartoon_train_dataset, cartoon_test_dataset = torch.utils.data.random_split(cartoon_dataset, [1875, 469])\n",
    "sketch_train_dataset, sketch_test_dataset = torch.utils.data.random_split(sketch_dataset, [3143, 786])\n",
    "\n",
    "# concated_train_dataset = ConcatDataset([photo_train_dataset, art_train_dataset, cartoon_train_dataset, sketch_train_dataset])\n",
    "# concated_test_dataset = ConcatDataset([photo_test_dataset, art_test_dataset, cartoon_test_dataset, sketch_test_dataset])\n",
    "concated_train_dataset = ConcatDataset([art_train_dataset, sketch_train_dataset, photo_train_dataset])\n",
    "# concated_test_dataset = ConcatDataset([sketch_test_dataset, art_test_dataset, cartoon_test_dataset])\n",
    "concated_train_domain = torch.vstack((torch.full((len(art_dataset), 1), 1), torch.full((len(sketch_dataset), 1), 2), torch.full((len(photo_dataset), 1), 3)))\n",
    "train_loader = DataLoader(list(zip(concated_train_dataset, concated_train_domain)), batch_size=32, shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(cartoon_dataset, batch_size=32, shuffle=False, num_workers=8)\n",
    "# test_loader = DataLoader(concated_test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixStyle(nn.Module):\n",
    "    \"\"\"MixStyle.\n",
    "    Reference:\n",
    "      Zhou et al. Domain Generalization with MixStyle. ICLR 2021.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5, alpha=0.1, eps=1e-6, mix='random'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          p (float): probability of using MixStyle.\n",
    "          alpha (float): parameter of the Beta distribution.\n",
    "          eps (float): scaling parameter to avoid numerical issues.\n",
    "          mix (str): how to mix.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.beta = torch.distributions.Beta(alpha, alpha)\n",
    "        self.eps = eps\n",
    "        self.alpha = alpha\n",
    "        self.mix = mix\n",
    "        self._activated = True\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MixStyle(p={self.p}, alpha={self.alpha}, eps={self.eps}, mix={self.mix})'\n",
    "\n",
    "    def set_activation_status(self, status=True):\n",
    "        self._activated = status\n",
    "\n",
    "    def update_mix_method(self, mix='random'):\n",
    "        self.mix = mix\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training or not self._activated:\n",
    "            return x\n",
    "\n",
    "        if random.random() > self.p:\n",
    "            return x\n",
    "\n",
    "        B = x.size(0)\n",
    "\n",
    "        mu = x.mean(dim=[2, 3], keepdim=True)\n",
    "        var = x.var(dim=[2, 3], keepdim=True)\n",
    "        sig = (var + self.eps).sqrt()\n",
    "        mu, sig = mu.detach(), sig.detach()\n",
    "        x_normed = (x-mu) / sig\n",
    "\n",
    "        lmda = self.beta.sample((B, 1, 1, 1))\n",
    "        lmda = lmda.to(x.device)\n",
    "\n",
    "        if self.mix == 'random':\n",
    "            # random shuffle\n",
    "            perm = torch.randperm(B)\n",
    "\n",
    "        elif self.mix == 'crossdomain':\n",
    "            # split into two halves and swap the order\n",
    "            perm = torch.arange(B - 1, -1, -1) # inverse index\n",
    "            perm_b, perm_a = perm.chunk(2)\n",
    "            perm_b = perm_b[torch.randperm(B // 2)]\n",
    "            perm_a = perm_a[torch.randperm(B // 2)]\n",
    "            perm = torch.cat([perm_b, perm_a], 0)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        mu2, sig2 = mu[perm], sig[perm]\n",
    "        mu_mix = mu*lmda + mu2 * (1-lmda)\n",
    "        sig_mix = sig*lmda + sig2 * (1-lmda)\n",
    "\n",
    "        return x_normed*sig_mix + mu_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributionUncertainty(nn.Module):\n",
    "    \"\"\"\n",
    "    Distribution Uncertainty Module\n",
    "        Args:\n",
    "        p   (float): probabilty of foward distribution uncertainty module, p in [0,1].\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5, eps=1e-6):\n",
    "        super(DistributionUncertainty, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.p = p\n",
    "        self.factor = 1.0\n",
    "\n",
    "    def _reparameterize(self, mu, std):\n",
    "        epsilon = torch.randn_like(std) * self.factor\n",
    "        return mu + epsilon * std\n",
    "\n",
    "    def sqrtvar(self, x):\n",
    "        t = (x.var(dim=0, keepdim=True) + self.eps).sqrt()\n",
    "        t = t.repeat(x.shape[0], 1)\n",
    "        return t\n",
    "\n",
    "    def forward(self, x):\n",
    "        if (not self.training) or (np.random.random()) > self.p:\n",
    "            return x\n",
    "\n",
    "        mean = x.mean(dim=[2, 3], keepdim=False)\n",
    "        std = (x.var(dim=[2, 3], keepdim=False) + self.eps).sqrt()\n",
    "\n",
    "        sqrtvar_mu = self.sqrtvar(mean)\n",
    "        sqrtvar_std = self.sqrtvar(std)\n",
    "\n",
    "        beta = self._reparameterize(mean, sqrtvar_mu)\n",
    "        gamma = self._reparameterize(std, sqrtvar_std)\n",
    "\n",
    "        x = (x - mean.reshape(x.shape[0], x.shape[1], 1, 1)) / std.reshape(x.shape[0], x.shape[1], 1, 1)\n",
    "        x = x * gamma.reshape(x.shape[0], x.shape[1], 1, 1) + beta.reshape(x.shape[0], x.shape[1], 1, 1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantStyle(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mean = []\n",
    "        self.std = []\n",
    "        self.eps = eps\n",
    "        self.const_mean = None\n",
    "        self.const_std = None\n",
    "        self.domain_list = []\n",
    "    \n",
    "    def clear_memory(self):\n",
    "        self.mean = []\n",
    "        self.std = []\n",
    "        self.domain_list = []\n",
    "        \n",
    "    def get_style(self, x):\n",
    "        mu = x.mean(dim=[2, 3], keepdim=True)\n",
    "        var = x.var(dim=[2, 3], keepdim=True)\n",
    "        var = var.sqrt()\n",
    "        mu, var = mu.detach().squeeze(), var.detach().squeeze()\n",
    "        \n",
    "        return mu, var\n",
    "    \n",
    "    def store_style(self, x, domains):\n",
    "        mu, var = self.get_style(x)\n",
    "        self.mean.extend(mu)\n",
    "        self.std.extend(var)\n",
    "        self.domain_list.extend([i.item() for i in domains])\n",
    "    \n",
    "    def clustering(self, round):\n",
    "        mean = torch.vstack(self.mean)\n",
    "        std = torch.vstack(self.std)\n",
    "        tsne = TSNE(n_components=1, random_state=42)\n",
    "        transformed_mean = tsne.fit_transform(mean.detach().cpu().numpy())\n",
    "\n",
    "        tsne2 = TSNE(n_components=1, random_state=42)\n",
    "        transformed_std = tsne2.fit_transform(std.detach().cpu().numpy())\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.scatter(transformed_mean[:, 0], transformed_std[:, 0])\n",
    "        plt.savefig(f'mean_std_round{round}.png')\n",
    "        \n",
    "        data = torch.cat((mean, std), dim=1).detach().cpu().numpy()\n",
    "        # neigh = NearestNeighbors(n_neighbors=2)\n",
    "        # nbrs = neigh.fit(data)\n",
    "        # distances, indices = nbrs.kneighbors(data)\n",
    "        # distances = np.sort(distances, axis=0)\n",
    "        # distances = distances[:,1]\n",
    "        # plt.figure(figsize=(20,10))\n",
    "        # plt.plot(distances)\n",
    "        dbscan = DBSCAN(eps=5, min_samples=50)\n",
    "        # dbscan = KMeans(n_clusters=3, n_init=50)\n",
    "        dbscan.fit(data)\n",
    "        \n",
    "        labels = dbscan.labels_\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        # print(f'Total cluster: {n_clusters}')\n",
    "        \n",
    "        sample_each_label = [len(labels[labels == i]) for i in range(n_clusters)]\n",
    "        largest_cluster = np.argmax(sample_each_label)\n",
    "        cluster_mean = mean[labels == largest_cluster]\n",
    "        cluster_std = std[labels == largest_cluster]\n",
    "        self.const_mean = torch.mean(cluster_mean, axis=0)\n",
    "        self.const_std = torch.mean(cluster_std, axis=0)\n",
    "    \n",
    "    def cal_mean_std(self, id):\n",
    "        domain_list = np.array(self.domain_list)\n",
    "        idx_val = np.where(domain_list == id)[0]\n",
    "        cluster_mean = [self.mean[i] for i in idx_val]\n",
    "        cluster_std = [self.std[i] for i in idx_val]\n",
    "        cluster_mean = torch.stack(cluster_mean)\n",
    "        cluster_std = torch.stack(cluster_std)\n",
    "        \n",
    "        self.const_mean = torch.mean(cluster_mean, axis=0)\n",
    "        self.const_std = torch.mean(cluster_std, axis=0)\n",
    "            \n",
    "    \n",
    "    def forward(self, x, test=False):\n",
    "        mu = x.mean(dim=[2, 3], keepdim=True)\n",
    "        var = x.var(dim=[2, 3], keepdim=True)\n",
    "        sig = (var + self.eps).sqrt()\n",
    "        mu, sig = mu.detach(), sig.detach()\n",
    "        x_normed = (x-mu) / sig\n",
    "        const_mean = torch.reshape(self.const_mean, (1, self.const_mean.shape[0], 1, 1))\n",
    "        const_std = torch.reshape(self.const_std, (1, self.const_std.shape[0], 1, 1))\n",
    "        out = x_normed * const_std + const_mean\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleIntergratedModel(nn.Module):\n",
    "    def __init__(self, num_style=2):\n",
    "        super().__init__()\n",
    "        model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.model = model\n",
    "        self.mixstyle = MixStyle(p=0.8, alpha=0.1)\n",
    "        self.num_style = num_style\n",
    "        self.conststyle = [ConstantStyle() for i in range(self.num_style)]\n",
    "        self.mean = []\n",
    "        self.std = []\n",
    "        self.const_mean = None\n",
    "        self.const_std = None\n",
    "    \n",
    "    def forward(self, x, domains, const_style=False, store_style=False, test=False):\n",
    "        x = self.model.conv1(x)\n",
    "        # x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "\n",
    "        x = self.model.layer1(x)\n",
    "        if store_style:\n",
    "            self.conststyle[0].store_style(x, domains)\n",
    "        if const_style:\n",
    "            x = self.conststyle[0](x, test=test)\n",
    "        x = self.model.layer2(x)\n",
    "        if store_style:\n",
    "            self.conststyle[1].store_style(x, domains)\n",
    "        if const_style:\n",
    "            x = self.conststyle[1](x, test=test)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "\n",
    "        x = self.model.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.model.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixStyleModel(nn.Module):\n",
    "    def __init__(self, num_style=2):\n",
    "        super().__init__()\n",
    "        model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.model = model\n",
    "        self.mixstyle = MixStyle(p=0.5, alpha=0.1)\n",
    "        self.num_style = num_style\n",
    "        self.mean = []\n",
    "        self.std = []\n",
    "        self.const_mean = None\n",
    "        self.const_std = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        # x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.mixstyle(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.mixstyle(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "\n",
    "        x = self.model.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.model.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "model = StyleIntergratedModel()\n",
    "model.model.fc = torch.nn.Linear(model.model.fc.in_features, 7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "model2 = MixStyleModel()\n",
    "model2.model.fc = torch.nn.Linear(model2.model.fc.in_features, 7)\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, ConstStyle Loss: 0.1305159519057876 | MixStyle Loss: 0.21563147540049007\n",
      "ConstStyle Accuracy: 70.39% | MixStyle Accuracy: 67.24%\n",
      "Epoch 2/50, ConstStyle Loss: 0.13874749200961864 | MixStyle Loss: 0.11575003642550048\n",
      "ConstStyle Accuracy: 75.17% | MixStyle Accuracy: 74.49%\n",
      "Epoch 3/50, ConstStyle Loss: 0.045971750987519044 | MixStyle Loss: 0.06834541510033887\n",
      "ConstStyle Accuracy: 74.79% | MixStyle Accuracy: 71.93%\n",
      "Epoch 4/50, ConstStyle Loss: 0.013806903444371224 | MixStyle Loss: 0.0529746399843134\n",
      "ConstStyle Accuracy: 76.54% | MixStyle Accuracy: 72.99%\n",
      "Epoch 5/50, ConstStyle Loss: 0.005755505637656218 | MixStyle Loss: 0.04008968979906058\n",
      "ConstStyle Accuracy: 76.96% | MixStyle Accuracy: 69.71%\n",
      "Epoch 6/50, ConstStyle Loss: 0.0033775337509117285 | MixStyle Loss: 0.04303525521148307\n",
      "ConstStyle Accuracy: 77.69% | MixStyle Accuracy: 70.61%\n",
      "Epoch 7/50, ConstStyle Loss: 0.003541156085248076 | MixStyle Loss: 0.035517664236977\n",
      "ConstStyle Accuracy: 77.60% | MixStyle Accuracy: 72.31%\n",
      "Epoch 8/50, ConstStyle Loss: 0.007443051828280052 | MixStyle Loss: 0.034140538336335645\n",
      "ConstStyle Accuracy: 77.69% | MixStyle Accuracy: 77.60%\n",
      "Epoch 9/50, ConstStyle Loss: 0.0037165535375910017 | MixStyle Loss: 0.018768678309546278\n",
      "ConstStyle Accuracy: 75.98% | MixStyle Accuracy: 72.27%\n",
      "Epoch 10/50, ConstStyle Loss: 0.01344726250469345 | MixStyle Loss: 0.019301595542553212\n",
      "ConstStyle Accuracy: 74.66% | MixStyle Accuracy: 71.97%\n",
      "Epoch 11/50, ConstStyle Loss: 0.060012394521133196 | MixStyle Loss: 0.021416121194609634\n",
      "ConstStyle Accuracy: 68.73% | MixStyle Accuracy: 69.80%\n",
      "Epoch 12/50, ConstStyle Loss: 0.03105324675925658 | MixStyle Loss: 0.019635325256482854\n",
      "ConstStyle Accuracy: 76.28% | MixStyle Accuracy: 75.34%\n",
      "Epoch 13/50, ConstStyle Loss: 0.041721841210043444 | MixStyle Loss: 0.019127044379577757\n",
      "ConstStyle Accuracy: 80.20% | MixStyle Accuracy: 74.53%\n",
      "Epoch 14/50, ConstStyle Loss: 0.0157449109413695 | MixStyle Loss: 0.015394585898926985\n",
      "ConstStyle Accuracy: 75.60% | MixStyle Accuracy: 71.03%\n",
      "Epoch 15/50, ConstStyle Loss: 0.007193962415612987 | MixStyle Loss: 0.041586154943919006\n",
      "ConstStyle Accuracy: 72.74% | MixStyle Accuracy: 72.06%\n",
      "Epoch 16/50, ConstStyle Loss: 0.023575483432826633 | MixStyle Loss: 0.024290640519969504\n",
      "ConstStyle Accuracy: 74.62% | MixStyle Accuracy: 74.40%\n",
      "Epoch 17/50, ConstStyle Loss: 0.005766792048158702 | MixStyle Loss: 0.014391668116635023\n",
      "ConstStyle Accuracy: 74.15% | MixStyle Accuracy: 71.93%\n",
      "Epoch 18/50, ConstStyle Loss: 0.009257673309927364 | MixStyle Loss: 0.015715905676339997\n",
      "ConstStyle Accuracy: 75.26% | MixStyle Accuracy: 71.16%\n",
      "Epoch 19/50, ConstStyle Loss: 0.0044665931154668215 | MixStyle Loss: 0.013180964264771925\n",
      "ConstStyle Accuracy: 75.98% | MixStyle Accuracy: 69.41%\n",
      "Epoch 20/50, ConstStyle Loss: 0.008165307751293463 | MixStyle Loss: 0.03088086996194761\n",
      "ConstStyle Accuracy: 74.36% | MixStyle Accuracy: 72.27%\n",
      "Epoch 21/50, ConstStyle Loss: 0.002459507607075769 | MixStyle Loss: 0.014058080100236717\n",
      "ConstStyle Accuracy: 76.32% | MixStyle Accuracy: 72.35%\n",
      "Epoch 22/50, ConstStyle Loss: 0.006760564142799315 | MixStyle Loss: 0.030614507959398907\n",
      "ConstStyle Accuracy: 75.04% | MixStyle Accuracy: 72.40%\n",
      "Epoch 23/50, ConstStyle Loss: 0.0026684570411058908 | MixStyle Loss: 0.010090447961639862\n",
      "ConstStyle Accuracy: 73.72% | MixStyle Accuracy: 70.48%\n",
      "Epoch 24/50, ConstStyle Loss: 0.006563933284477723 | MixStyle Loss: 0.014182778133924026\n",
      "ConstStyle Accuracy: 60.79% | MixStyle Accuracy: 72.35%\n",
      "Epoch 25/50, ConstStyle Loss: 0.03251996038428236 | MixStyle Loss: 0.01027502712971303\n",
      "ConstStyle Accuracy: 75.09% | MixStyle Accuracy: 71.25%\n",
      "Epoch 26/50, ConstStyle Loss: 0.013480154389678015 | MixStyle Loss: 0.01077981983189602\n",
      "ConstStyle Accuracy: 71.12% | MixStyle Accuracy: 68.94%\n",
      "Epoch 27/50, ConstStyle Loss: 0.009654930670800846 | MixStyle Loss: 0.007163383775264265\n",
      "ConstStyle Accuracy: 76.83% | MixStyle Accuracy: 72.53%\n",
      "Epoch 28/50, ConstStyle Loss: 0.005787000077418725 | MixStyle Loss: 0.009856044770155373\n",
      "ConstStyle Accuracy: 75.85% | MixStyle Accuracy: 72.06%\n",
      "Epoch 29/50, ConstStyle Loss: 0.025885105704901434 | MixStyle Loss: 0.02771902798266031\n",
      "ConstStyle Accuracy: 69.20% | MixStyle Accuracy: 69.28%\n",
      "Epoch 30/50, ConstStyle Loss: 0.033949646318433224 | MixStyle Loss: 0.010961539416257438\n",
      "ConstStyle Accuracy: 75.85% | MixStyle Accuracy: 72.87%\n",
      "Epoch 31/50, ConstStyle Loss: 0.00774859106581971 | MixStyle Loss: 0.010311824822527646\n",
      "ConstStyle Accuracy: 72.10% | MixStyle Accuracy: 72.87%\n",
      "Epoch 32/50, ConstStyle Loss: 0.003391390533276232 | MixStyle Loss: 0.04207461912604534\n",
      "ConstStyle Accuracy: 76.58% | MixStyle Accuracy: 72.74%\n",
      "Epoch 33/50, ConstStyle Loss: 0.004829460404456161 | MixStyle Loss: 0.016836382653233766\n",
      "ConstStyle Accuracy: 74.10% | MixStyle Accuracy: 73.04%\n",
      "Epoch 34/50, ConstStyle Loss: 0.005267908191929867 | MixStyle Loss: 0.004112428307432007\n",
      "ConstStyle Accuracy: 75.04% | MixStyle Accuracy: 70.73%\n",
      "Epoch 35/50, ConstStyle Loss: 0.0041707727898862386 | MixStyle Loss: 0.006211526611347533\n",
      "ConstStyle Accuracy: 75.90% | MixStyle Accuracy: 72.78%\n",
      "Epoch 36/50, ConstStyle Loss: 0.003545252778299831 | MixStyle Loss: 0.0029559534226943165\n",
      "ConstStyle Accuracy: 75.43% | MixStyle Accuracy: 73.68%\n",
      "Epoch 37/50, ConstStyle Loss: 0.022812115196757077 | MixStyle Loss: 0.007054202228118811\n",
      "ConstStyle Accuracy: 70.22% | MixStyle Accuracy: 72.95%\n",
      "Epoch 38/50, ConstStyle Loss: 0.00581293975524962 | MixStyle Loss: 0.026086043032288824\n",
      "ConstStyle Accuracy: 70.18% | MixStyle Accuracy: 76.54%\n",
      "Epoch 39/50, ConstStyle Loss: 0.008135883928067264 | MixStyle Loss: 0.008724709527427876\n",
      "ConstStyle Accuracy: 72.44% | MixStyle Accuracy: 71.93%\n",
      "Epoch 40/50, ConstStyle Loss: 0.00520012524430058 | MixStyle Loss: 0.007001490169917209\n",
      "ConstStyle Accuracy: 74.79% | MixStyle Accuracy: 71.16%\n",
      "Epoch 41/50, ConstStyle Loss: 0.016205062858697755 | MixStyle Loss: 0.011484183571231673\n",
      "ConstStyle Accuracy: 73.98% | MixStyle Accuracy: 75.43%\n",
      "Epoch 42/50, ConstStyle Loss: 0.008982121840801938 | MixStyle Loss: 0.02151904533523445\n",
      "ConstStyle Accuracy: 76.49% | MixStyle Accuracy: 69.75%\n",
      "Epoch 43/50, ConstStyle Loss: 0.006536999462999423 | MixStyle Loss: 0.004696969484314195\n",
      "ConstStyle Accuracy: 72.65% | MixStyle Accuracy: 73.08%\n",
      "Epoch 44/50, ConstStyle Loss: 0.0030601871836021624 | MixStyle Loss: 0.0020854395972946804\n",
      "ConstStyle Accuracy: 72.31% | MixStyle Accuracy: 73.08%\n",
      "Epoch 45/50, ConstStyle Loss: 0.015159875792543668 | MixStyle Loss: 0.014463462146740843\n",
      "ConstStyle Accuracy: 75.94% | MixStyle Accuracy: 70.65%\n",
      "Epoch 46/50, ConstStyle Loss: 0.04121489089463163 | MixStyle Loss: 0.039683866091081654\n",
      "ConstStyle Accuracy: 76.54% | MixStyle Accuracy: 68.17%\n",
      "Epoch 47/50, ConstStyle Loss: 0.006517470033202244 | MixStyle Loss: 0.008802773180794551\n",
      "ConstStyle Accuracy: 73.98% | MixStyle Accuracy: 71.37%\n",
      "Epoch 48/50, ConstStyle Loss: 0.0018228259892604608 | MixStyle Loss: 0.005539053094253177\n",
      "ConstStyle Accuracy: 74.66% | MixStyle Accuracy: 73.72%\n",
      "Epoch 49/50, ConstStyle Loss: 0.0029931255125461576 | MixStyle Loss: 0.001982406810526527\n",
      "ConstStyle Accuracy: 77.77% | MixStyle Accuracy: 76.19%\n",
      "Epoch 50/50, ConstStyle Loss: 0.0010664855700497355 | MixStyle Loss: 0.005108894897280909\n",
      "ConstStyle Accuracy: 75.73% | MixStyle Accuracy: 72.40%\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model2.to(device)\n",
    "stored_label = []\n",
    "for epoch in range(num_epoch):\n",
    "    for conststyle in model.conststyle:\n",
    "        conststyle.clear_memory()\n",
    "        \n",
    "    model.train()\n",
    "    model2.train()\n",
    "    running_loss = 0.0\n",
    "    running_loss2 = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels, domains = inputs[0].to(device), inputs[1].to(device), labels\n",
    "        optimizer.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "            \n",
    "        stored_label.extend(labels.detach().cpu())\n",
    "        \n",
    "        \n",
    "        if epoch == 0:\n",
    "            outputs = model(inputs, domains, store_style=True)\n",
    "        else:\n",
    "            outputs = model(inputs, domains, const_style=True, store_style=True)\n",
    "        \n",
    "        outputs2 = model2(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss2 = criterion2(outputs2, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        loss2.backward()\n",
    "        optimizer.step()\n",
    "        optimizer2.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_loss2 += loss2.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        for conststyle in model.conststyle:\n",
    "            conststyle.cal_mean_std(2)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epoch}, ConstStyle Loss: {running_loss/len(train_loader)} | MixStyle Loss: {running_loss2/len(train_loader)}\")\n",
    "\n",
    "    model.eval()\n",
    "    model2.eval()\n",
    "    correct_predictions = 0\n",
    "    correct_predictions2 = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs, domains, const_style=True, test=True)\n",
    "            outputs2 = model2(inputs)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            _, predicted2 = torch.max(outputs2, 1)\n",
    "            correct_predictions2 += (predicted2 == labels).sum().item()\n",
    "\n",
    "    # Calculate test accuracy\n",
    "    test_accuracy = correct_predictions / total_samples\n",
    "    test_accuracy2 = correct_predictions2 / total_samples\n",
    "    print(f\"ConstStyle Accuracy: {test_accuracy * 100:.2f}% | MixStyle Accuracy: {test_accuracy2 * 100:.2f}%\")\n",
    "\n",
    "print(\"Training finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(device)\n",
    "# stored_label = []\n",
    "# for epoch in range(num_epoch):        \n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for inputs, labels in train_loader:\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "            \n",
    "#         stored_label.extend(labels.detach().cpu())\n",
    "#         outputs = model(inputs)\n",
    "            \n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}/{num_epoch}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "#     model.eval()\n",
    "#     correct_predictions = 0\n",
    "#     total_samples = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#             # Forward pass\n",
    "#             outputs = model(inputs)\n",
    "\n",
    "#             # Calculate accuracy\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             total_samples += labels.size(0)\n",
    "#             correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "#     # Calculate test accuracy\n",
    "#     test_accuracy = correct_predictions / total_samples\n",
    "#     print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and plot domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['sketch', 'art', 'cartoon']\n",
    "scatter = plt.scatter(transformed_mean[:, 0], transformed_std[:, 0], c=stored_label)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=classes)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityLayer(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(IdentityLayer, self).__init__()\n",
    "        self.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer2 = nn.Identity()\n",
    "model.layer3 = nn.Identity()\n",
    "model.layer4 = nn.Identity()\n",
    "model.avgpool = nn.Identity()\n",
    "model.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_image_idx = [[] for _ in range(7)]\n",
    "art_image_idx = [[] for _ in range(7)]\n",
    "cartoon_image_idx = [[] for _ in range(7)]\n",
    "sketch_image_idx = [[] for _ in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    for idx, val in enumerate(photo_dataset.targets):\n",
    "        if val == i:\n",
    "            photo_image_idx[i].append(idx)\n",
    "    for idx, val in enumerate(art_dataset.targets):\n",
    "        if val == i:\n",
    "            art_image_idx[i].append(idx)\n",
    "    for idx, val in enumerate(cartoon_dataset.targets):\n",
    "        if val == i:\n",
    "            cartoon_image_idx[i].append(idx)\n",
    "    for idx, val in enumerate(sketch_dataset.targets):\n",
    "        if val == i:\n",
    "            sketch_image_idx[i].append(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get random 50 samples of all domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dl_list = []\n",
    "for i in range(7):\n",
    "    photo_idx = np.random.choice(photo_image_idx[i], 50)\n",
    "    art_idx = np.random.choice(art_image_idx[i], 50)\n",
    "    cartoon_idx = np.random.choice(cartoon_image_idx[i], 50)\n",
    "    sketch_idx = np.random.choice(sketch_image_idx[i], 50)\n",
    "    \n",
    "    photo_subset = Subset(photo_dataset, photo_idx)\n",
    "    art_subset = Subset(art_dataset, art_idx)\n",
    "    cartoon_subset = Subset(cartoon_dataset, cartoon_idx)\n",
    "    sketch_subset = Subset(sketch_dataset, sketch_idx)\n",
    "    \n",
    "    class_dataset = ConcatDataset([photo_subset, art_subset, cartoon_subset, sketch_subset])\n",
    "    class_dl = DataLoader(class_dataset, batch_size=50, shuffle=False)\n",
    "    class_dl_list.append(class_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get random 50 samples of testing domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_list = []\n",
    "# for i in range(7):\n",
    "#     sketch_idx = np.random.choice(sketch_image_idx[i], 50)    \n",
    "#     sketch_subset = Subset(sketch_dataset, sketch_idx)\n",
    "#     subset_list.append(sketch_subset)\n",
    "\n",
    "# class_dataset = ConcatDataset(subset_list)\n",
    "# class_dl = DataLoader(class_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move samples of test domain to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_feats = []\n",
    "# total_labels = []\n",
    "# i = 0\n",
    "# model.to(device)\n",
    "# for images, labels in class_dl:\n",
    "#     images, labels = images.to(device), labels.to(device)\n",
    "#     feats = model(images)\n",
    "#     total_labels.extend(labels.cpu().detach().numpy())\n",
    "#     total_feats.append(feats.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move samples of all domains to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_feats = []\n",
    "total_labels = []\n",
    "i = 0\n",
    "model.to('cpu')\n",
    "for images, labels in class_dl_list[6]:\n",
    "    feats = model(images)\n",
    "    feats = feats.reshape((50, 64, 56, 56))\n",
    "    # feats = feats.reshape((50, 128, 28, 28))\n",
    "    # feats = feats.reshape((50, 256, 14, 14))\n",
    "    # feats = feats.reshape((50, 512, 7, 7))\n",
    "    print(feats.shape)\n",
    "    total_labels.extend([i for _ in range(50)])\n",
    "    total_feats.append(feats.cpu().detach().numpy())\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_feats = np.vstack(total_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne = TSNE(n_components=2, random_state=42)\n",
    "# transformed_feats = tsne.fit_transform(total_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(transformed_feats[:, 0], transformed_feats[:, 1], c=total_labels)\n",
    "# plt.legend(['photo', 'art'])\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(total_feats, axis=(2, 3), keepdims=True)\n",
    "std = np.std(total_feats, axis=(2, 3), keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.squeeze(mean)\n",
    "std = np.squeeze(std)\n",
    "\n",
    "print(mean.shape, std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./mean_value.npy', mean)\n",
    "np.save('./std_value.npy', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_feats = np.concatenate([mean[:, np.newaxis, :], std[:, np.newaxis, :]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=1, random_state=42)\n",
    "transformed_mean = tsne.fit_transform(mean)\n",
    "\n",
    "tsne2 = TSNE(n_components=1, random_state=42)\n",
    "transformed_std = tsne2.fit_transform(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['photo', 'art', 'cartoon', 'sketch']\n",
    "scatter = plt.scatter(transformed_mean[:, 0], transformed_std[:, 0], c=total_labels)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=classes)\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ndg2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
